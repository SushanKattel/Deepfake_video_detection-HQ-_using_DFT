{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deepfake_Part2-Testing.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1HqBKC7UvMI",
        "outputId": "8a1ec3af-20d1-482c-bd46-80bb95c0220e"
      },
      "source": [
        "# Mounting Google Colab with Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuTKBt96U1ta"
      },
      "source": [
        "# Moving to the directory of radialProfile.py so we can import it below\n",
        "\n",
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/deepfake/Frequency/Faces-HQ\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPO-JciIVJ90"
      },
      "source": [
        "# Importing Other Required Modules\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import radialProfile\n",
        "import glob\n",
        "from matplotlib import pyplot as plt\n",
        "import pickle\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWFXmEHbVNHi"
      },
      "source": [
        "# load the model from disk. (Here, we are using svc model. Using linear reg. model is exactly similar)\n",
        "loaded_model = pickle. load(open('finalized_svc_model_1.sav', 'rb'))\n",
        "\n",
        "# loaded_model_lr = pickle. load(open('finalized_lr_model_1.sav', 'rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJbkeHtsVR1T"
      },
      "source": [
        "# Load the Cascade classifier to detect face from disk\n",
        "\n",
        "classifier = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBdmFkEbVsK-",
        "outputId": "7869c939-f1ba-490d-97c1-536b2c9eb34e"
      },
      "source": [
        "\n",
        "video = cv2.VideoCapture('deepfake1.mkv')  # Load the video File\n",
        "\n",
        "epsilon = 1e-8                         # A small constant Epsilon, used as in previous for preprocessing\n",
        "prediction_list=[]                     # An empty list initialized to take the predictions from face of each frame\n",
        "j=0                                    # Here, we are taking only first 100 frames, so initializing the variable for count\n",
        "\n",
        "while (j<=100):\n",
        "    j=j+1\n",
        "    (f, im) = video.read() # f returns only True, False according to video access\n",
        "   \n",
        "\n",
        "    if f != True:         # If f is not true i.e., no frame is found, break the operation\n",
        "       break\n",
        "\n",
        "\n",
        "    # detectfaces using haarcascade_frontalface classifier\n",
        "    faces = classifier.detectMultiScale(\n",
        "        im, # stream \n",
        "        scaleFactor=1.10, # change these parameters to improve your video processing performance\n",
        "        minNeighbors=20, \n",
        "        minSize=(30, 30) # min image detection size\n",
        "        ) \n",
        "    \n",
        "    # Draw rectangles around each face\n",
        "    for (x, y, w, h) in faces:\n",
        "\n",
        "        # Saving faces according to detected coordinates, preprocessing them as on training datas and feeding them to classifier.\n",
        "        sub_face = im[y:y+h, x:x+w]\n",
        "        sub_face = cv2.cvtColor(sub_face, cv2.COLOR_BGR2GRAY)      # Since we need Gray images, we convert the BGR frame to Gray {OpenCv reads RGB image as BGR}\n",
        "        img = cv2.resize(sub_face, (1024, 1024))                   # We have trained on the image of 1024 * 1024 So, the image to be fed in classifier must be same.\n",
        "        f = np.fft.fft2(img)                                       # Applying Fourier Transform\n",
        "        fshift = np.fft.fftshift(f)                                # Shifting the Origin: On shifting the Origin, the low frequency components comes to center and High freq. component move towards the corner.\n",
        "\n",
        "        fshift += epsilon                                          # Adding small constant Epsilon \n",
        "\n",
        "        magnitude_spectrum = 20*np.log(np.abs(fshift))             # Calculating Magnitude Spectrum\n",
        "\n",
        "        \n",
        "        # Calculate the azimuthally averaged 1D power spectrum\n",
        "        psd1D = radialProfile.azimuthalAverage(magnitude_spectrum)\n",
        "        \n",
        "        var = psd1D.reshape(-1, 722)                              # Reshaping The data with empty label { As training data had label, it wants testing data to be of same shape}\n",
        "                                                                  # The label will then be predicted by the classifier trained before.\n",
        "\n",
        "        predicted = loaded_model.predict(var).astype(int)         # astype(int) changes the data to integer type\n",
        "        pre = predicted.tolist()                                  # tolist() changes the values on var 'predicted' to a list\n",
        "        prediction_list.append(pre)                               # Appending the values from var 'pre' the prediction_list {Empty list initialized before}\n",
        "                                                                  # On appending for many frames, we get nested list here\n",
        "\n",
        "video.release()         # Realeasing the video frames after completion\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "final_pred = []            # Initializing other empty list, final_pred to keep the final predicted value\n",
        "\n",
        "def reemovNestings(l):            # This functions removes the nesting from the list. Since we have got a nested list before, we need to remove nestings.\n",
        "    for i in l:\n",
        "        if type(i) == list:\n",
        "            reemovNestings(i)\n",
        "        else:\n",
        "            final_pred.append(i)\n",
        "\n",
        "reemovNestings(prediction_list)     # Now, we get a list without the nestings\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# For the final prediction, we count the vote on each frame and the maximum number of vote we get is the final prediction.\n",
        "# i.e., If maximum frames are predicted fake, Final output is fake or vice versa.\n",
        "\n",
        "def max_rep(final_pred):      # This Function is for counting the maximum repeated value in list.     \n",
        "    counter = 0\n",
        "    num = final_pred[0]\n",
        "      \n",
        "    for i in final_pred:\n",
        "        curr_frequency = final_pred.count(i)\n",
        "        if(curr_frequency> counter):\n",
        "            counter = curr_frequency\n",
        "            num = i\n",
        "  \n",
        "    return num\n",
        "\n",
        "\n",
        "a = max_rep(final_pred)       # Here, we get the maximum repeated prediction\n",
        "\n",
        "\n",
        "# Now, Printing statement according to predicted value\n",
        "if a == 0:\n",
        "  print(\"The video is NOT from DEEPFAKE\")\n",
        "\n",
        "else:\n",
        "    print(\"The video is from DEEPFAKE\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The video is from DEEPFAKE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDvpda_kbWmo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}